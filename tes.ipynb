{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5c6c2f",
   "metadata": {},
   "source": [
    "## 1. Labelling Vehicle and Segmentation\n",
    "This method using SSD and U-Net. For identification vehicle's ID, we use StrongSORT based on that appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a66f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libabry yang dibutuhkan\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6869033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98489977",
   "metadata": {},
   "source": [
    "## 2. Detection Objek Using SSD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4208a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Amel Cantik\\Semester 4\\PKAC - Amelia Syahla Aurellia Sambudi\\Final Project CV\\.venv\\Lib\\site-packages\\torch\\hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to C:\\Users\\ACER/.cache\\torch\\hub\\torchhub.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\ACER/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\ACER/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssd_pyt_ckpt_amp/versions/20.06.0/files/nvidia_ssdpyt_amp_200703.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the SSD model from NVIDIA's PyTorch Hub\n",
    "try:\n",
    "    # Make sure you are connected to the internet for the first download\n",
    "    ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n",
    "    utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "    print(\"NVIDIA SSD model and processing utilities loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model from PyTorch Hub: {e}\")\n",
    "    print(\"Please ensure you have an internet connection and the repository/model is accessible.\")\n",
    "    ssd_model = None\n",
    "    utils = None\n",
    "\n",
    "if ssd_model:\n",
    "    # Move model to GPU if available, otherwise CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ssd_model.to(device)\n",
    "    ssd_model.eval() # Set the model to evaluation mode\n",
    "    print(f\"Model moved to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbdbdd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "PROTOTXT_PATH = \"models/mobilenet_ssd/deploy.prototxt\"\n",
    "MODEL_PATH = \"models/mobilenet_ssd/mobilenet_iter_73000.caffemodel\"\n",
    "# Ensure this VIDEO_DIR is correct relative to where your .ipynb file is saved.\n",
    "# If your .ipynb file is in \"FINAL PROJECT CV\", then \"Dataset\" should be a subdirectory.\n",
    "VIDEO_DIR = \"Dataset\"\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Minimum probability to filter weak detections\n",
    "\n",
    "# COCO class labels (MobileNet SSD is often trained on COCO)\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "        \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "        \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "        \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# Colors for bounding boxes\n",
    "CLASS_COLORS = {\n",
    "    \"car\": (0, 255, 0),  # Green\n",
    "    \"bus\": (255, 0, 0)   # Blue\n",
    "    # Add other class colors if needed\n",
    "}\n",
    "\n",
    "# Target classes for detection\n",
    "TARGET_CLASSES = [\"car\", \"bus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e79362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading SSD model...\n",
      "[INFO] SSD model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Load SSD Model ---\n",
    "print(\"[INFO] Loading SSD model...\")\n",
    "net = None # Initialize net\n",
    "try:\n",
    "    # Ensure the paths are correct relative to the notebook's location\n",
    "    if not os.path.exists(PROTOTXT_PATH):\n",
    "        print(f\"[ERROR] Prototxt file not found at: {os.path.abspath(PROTOTXT_PATH)}\")\n",
    "    elif not os.path.exists(MODEL_PATH):\n",
    "        print(f\"[ERROR] Model file not found at: {os.path.abspath(MODEL_PATH)}\")\n",
    "    else:\n",
    "        net = cv2.dnn.readNetFromCaffe(PROTOTXT_PATH, MODEL_PATH)\n",
    "        print(\"[INFO] SSD model loaded successfully.\")\n",
    "except cv2.error as e:\n",
    "    print(f\"[ERROR] Could not load SSD model.\")\n",
    "    print(f\"Attempted Prototxt: {os.path.abspath(PROTOTXT_PATH)}\")\n",
    "    print(f\"Attempted Caffemodel: {os.path.abspath(MODEL_PATH)}\")\n",
    "    print(f\"OpenCV error: {e}\")\n",
    "\n",
    "if net is None:\n",
    "    print(\"[WARNING] SSD Model could not be loaded. Video processing will not occur.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0746199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Placeholder for U-Net Model Loading and Processing ---\n",
    "# To integrate U-Net, you would typically:\n",
    "# 1. Load your pre-trained U-Net model here (e.g., TensorFlow, Keras, PyTorch, or OpenCV dnn)\n",
    "#    unet_model = cv2.dnn.readNetFromTensorflow('path/to/your/unet.pb') # Example\n",
    "# 2. Define a function to process a frame with U-Net.\n",
    "\n",
    "def apply_unet_processing(frame_input):\n",
    "    \"\"\"\n",
    "    Placeholder function for U-Net processing.\n",
    "    Replace this with your actual U-Net inference code.\n",
    "    \"\"\"\n",
    "    # Example: If U-Net performs segmentation, you might get a mask\n",
    "    # processed_unet_output = unet_model.forward(blob_from_unet_input(frame_input))\n",
    "    # segmented_mask = postprocess_unet_output(processed_unet_output)\n",
    "    # frame_with_unet_overlay = overlay_mask_on_frame(frame_input, segmented_mask)\n",
    "    # return frame_with_unet_overlay\n",
    "\n",
    "    # print(\"[INFO] U-Net processing placeholder: No U-Net model loaded or applied.\")\n",
    "    # For now, just return the frame as is\n",
    "    return frame_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687f17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found video files: ['Dataset\\\\vid1.mp4', 'Dataset\\\\vid2.mp4', 'Dataset\\\\vid3.mp4']\n",
      "\n",
      "[INFO] Processing video: Dataset\\vid1.mp4\n",
      "[INFO] End of video: vid1.mp4\n",
      "\n",
      "[INFO] Processing video: Dataset\\vid2.mp4\n",
      "[INFO] End of video: vid2.mp4\n",
      "\n",
      "[INFO] Processing video: Dataset\\vid3.mp4\n",
      "[INFO] End of video: vid3.mp4\n",
      "[INFO] Cleaning up any remaining OpenCV windows...\n",
      "--- End of Notebook Cell Execution ---\n"
     ]
    }
   ],
   "source": [
    "# --- Process Videos ---\n",
    "if net is None:\n",
    "    print(\"[ERROR] SSD Model not loaded. Cannot proceed with video processing.\")\n",
    "else:\n",
    "    # Check if VIDEO_DIR exists\n",
    "    if not os.path.isdir(VIDEO_DIR):\n",
    "        print(f\"[ERROR] Video directory not found: {os.path.abspath(VIDEO_DIR)}\")\n",
    "        video_files = []\n",
    "    else:\n",
    "        video_files = sorted([\n",
    "            os.path.join(VIDEO_DIR, f) for f in os.listdir(VIDEO_DIR)\n",
    "            if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')) # made it case-insensitive\n",
    "        ])\n",
    "\n",
    "    if not video_files:\n",
    "        if os.path.isdir(VIDEO_DIR):\n",
    "            print(f\"[INFO] No video files found in {os.path.abspath(VIDEO_DIR)}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Found video files: {video_files}\")\n",
    "\n",
    "        quit_all_processing = False\n",
    "        try:\n",
    "            for video_path in video_files:\n",
    "                if quit_all_processing:\n",
    "                    break\n",
    "\n",
    "                print(f\"\\n[INFO] Processing video: {video_path}\")\n",
    "                cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "                if not cap.isOpened():\n",
    "                    print(f\"[ERROR] Could not open video file: {video_path}\")\n",
    "                    continue\n",
    "\n",
    "                frame_count = 0\n",
    "                # Sanitize video name for window title (optional, but good practice)\n",
    "                base_video_name = os.path.basename(video_path)\n",
    "                window_name = f\"Output - {base_video_name}\"\n",
    "\n",
    "\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(f\"[INFO] End of video: {base_video_name}\")\n",
    "                        break\n",
    "\n",
    "                    frame_count += 1\n",
    "                    if frame is None: # Should be caught by 'not ret' but as a safeguard\n",
    "                        print(f\"[WARNING] Read an empty frame from {base_video_name} (frame {frame_count})\")\n",
    "                        continue\n",
    "                    \n",
    "                    (h, w) = frame.shape[:2]\n",
    "\n",
    "                    # --- SSD Detection ---\n",
    "                    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)),\n",
    "                                                0.007843, (300, 300), 127.5)\n",
    "                    net.setInput(blob)\n",
    "                    detections = net.forward()\n",
    "                    \n",
    "                    detected_objects_frame = frame.copy() # Work on a copy\n",
    "\n",
    "                    for i in np.arange(0, detections.shape[2]):\n",
    "                        confidence = detections[0, 0, i, 2]\n",
    "                        if confidence > CONFIDENCE_THRESHOLD:\n",
    "                            idx = int(detections[0, 0, i, 1])\n",
    "                            # Ensure idx is within bounds of CLASSES list\n",
    "                            if 0 <= idx < len(CLASSES):\n",
    "                                detected_class_name = CLASSES[idx]\n",
    "\n",
    "                                if detected_class_name in TARGET_CLASSES:\n",
    "                                    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                                    \n",
    "                                    color = CLASS_COLORS.get(detected_class_name, (0, 0, 255)) # Default to red\n",
    "                                    label = f\"{detected_class_name}: {confidence:.2f}\"\n",
    "                                    \n",
    "                                    cv2.rectangle(detected_objects_frame, (startX, startY), (endX, endY), color, 2)\n",
    "                                    y_label_pos = startY - 15 if startY - 15 > 15 else startY + 20 # Adjust label position\n",
    "                                    cv2.putText(detected_objects_frame, label, (startX, y_label_pos), \n",
    "                                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                            else:\n",
    "                                print(f\"[WARNING] Detected class index {idx} out of bounds for CLASSES list.\")\n",
    "                    \n",
    "                    # --- U-Net Processing (Placeholder) ---\n",
    "                    final_processed_frame = apply_unet_processing(detected_objects_frame)\n",
    "\n",
    "                    # --- Display the output frame ---\n",
    "                    # Ensure the window is created before trying to check its properties later\n",
    "                    cv2.imshow(window_name, final_processed_frame)\n",
    "                    key = cv2.waitKey(1) & 0xFF # waitKey(1) is crucial for video playback and event handling\n",
    "\n",
    "                    if key == ord(\"q\"):\n",
    "                        print(\"[INFO] 'q' pressed, quitting all processing...\")\n",
    "                        quit_all_processing = True\n",
    "                        break  # Break from inner loop (current video)\n",
    "                    elif key == ord(\"n\"):\n",
    "                        print(f\"[INFO] 'n' pressed, skipping to next video (from {base_video_name})...\")\n",
    "                        break  # Break from inner loop (current video)\n",
    "                \n",
    "                cap.release()\n",
    "                # Attempt to destroy the specific window for the video that just finished or was skipped.\n",
    "                # Check if window still exists before destroying, especially if 'q' was pressed.\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) >= 1:\n",
    "                    cv2.destroyWindow(window_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] An unexpected error occurred during video processing: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc() # Print full traceback for debugging\n",
    "        finally:\n",
    "            # This block executes whether the try block completes normally or an exception occurs.\n",
    "            print(\"[INFO] Cleaning up any remaining OpenCV windows...\")\n",
    "            cv2.destroyAllWindows()\n",
    "            # It can sometimes help in Jupyter to call waitKey a few times after destroyAllWindows\n",
    "            # to ensure the OS processes the window close events.\n",
    "            for _ in range(4): # Call it a few times\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "\n",
    "if net is not None and not video_files and os.path.isdir(VIDEO_DIR):\n",
    "    print(\"[INFO] Video processing loop finished or no videos were available to process.\")\n",
    "    cv2.destroyAllWindows() # Ensure cleanup if no videos run but model was loaded\n",
    "elif net is None:\n",
    "    print(\"[INFO] Model was not loaded, so no processing was attempted.\")\n",
    "\n",
    "print(\"--- End of Notebook Cell Execution ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe59d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
